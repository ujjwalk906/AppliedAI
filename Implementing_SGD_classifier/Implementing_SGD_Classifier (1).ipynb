{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing SGD Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e628ef3-c2d5-45df-8933-9c9f917ee3a9"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f3796b-d1cb-4b70-9a22-7552fdd7c18d"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5856134e-64a1-41f9-9d52-599612c6d9ad"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5dac37-ffce-4a99-b5b1-c292138eaf3b"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
            "Total training time: 0.17 seconds.\n",
            "Convergence after 14 epochs took 0.17 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343249cd-0f2c-476f-d238-40abad4b201a"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
              "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
              "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
              " (1, 15),\n",
              " array([-1.30580538]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "\n",
        "    w = np.zeros_like((dim))\n",
        "    b = 0\n",
        "\n",
        "    return w,b"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bef2de-8a56-42b7-c353-d4d447d8c0be"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8968551f-1dad-40b7-f90b-3fa3526867d2"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    sig = 1/(1+np.exp(-z))\n",
        "    return sig"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd03a53-f520-447b-b9b5-8d73da079407"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    n = len(y_true)\n",
        "    sum = 0\n",
        "    for i in range(len(y_true)):\n",
        "      sum = sum + (y_true[i]*np.log10(y_pred[i]) + (1-y_true[i])*np.log10(1-y_pred[i]))\n",
        "\n",
        "    loss = -1 * (1/n*sum)\n",
        "    return loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f96a4cc-7136-4ea7-e617-090b09323b73"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    w = np.array(w)\n",
        "    x = np.array(x)\n",
        "    sig_term = (np.transpose(w)*x) + b\n",
        "    dw = x*(y - sigmoid(sig_term))-(alpha/N)*w\n",
        "    return dw"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecf75a0-2dcc-4312-83be-6516ba2cad74"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     w = np.array(w)\n",
        "     x = np.array(x)\n",
        "     sig_term = (np.dot(w,x) + b)\n",
        "     db = y - sigmoid(sig_term)\n",
        "     return (db)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c37542-06ff-4bb2-f71e-e8ac8ff8700a"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tglnh4oxV8z-"
      },
      "source": [
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    # for every epoch\n",
        "        # for every data point(X_train,y_train)\n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "           #update w, b\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the train loss values in a list\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the test loss values in a list\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    grad_w,grad_b=initialize_weights(X_train[0])\n",
        "    w = grad_w\n",
        "    b = grad_b\n",
        "    N = len(X_train)\n",
        "    training_losses = []\n",
        "    test_losses =[]\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      for i in range(len(X_train)):\n",
        "        w = w + eta0*(gradient_dw(X_train[i],y_train[i],w,b,alpha,1))\n",
        "        b = b + eta0*(gradient_db(X_train[i],y_train[i],w,b))\n",
        "\n",
        "      predicted_outputs = []\n",
        "      for xis in X_train:\n",
        "        prediction = sigmoid(np.dot(w,xis)+b)\n",
        "        predicted_outputs.append(prediction)\n",
        "\n",
        "      training_loss = logloss(y_train,predicted_outputs)\n",
        "\n",
        "      training_losses.append(training_loss)\n",
        "\n",
        "      predicted_outputs = []\n",
        "      for xis in X_test:\n",
        "        prediction = sigmoid((np.dot(w,xis))+b)\n",
        "        predicted_outputs.append(prediction)\n",
        "\n",
        "      test_loss = logloss(y_test,predicted_outputs)\n",
        "      test_losses.append(test_loss)\n",
        "\n",
        "      # if epoch - 1 < 0:\n",
        "      #   continue\n",
        "      # elif training_losses[epoch] - training_losses[epoch - 1] <= 10**(-3):\n",
        "      #   break\n",
        "    \n",
        "    return w,b,training_losses,test_losses"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zi-24Ayl4cC",
        "outputId": "be1aa2f1-62aa-40a1-dab6-dcebdeca9297"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.39348337, -0.19771903, -0.15037836, -0.21528098, -1.28594363,\n",
              "       -0.66049132,  0.04140556, -0.22680269, -0.511055  , -0.42871073,\n",
              "        0.4210912 ,  0.22560347, -0.6624427 , -0.68888516,  0.56015427])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=14\n",
        "w,b,training_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfZfvNji7EFv",
        "outputId": "d12f4c9b-be98-4b4c-8755-edbc8dd84f98"
      },
      "source": [
        "training_loss"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20808124227206934,\n",
              " 0.19416462095514814,\n",
              " 0.19133705609772775,\n",
              " 0.19134029090115867,\n",
              " 0.19233542943660384,\n",
              " 0.19371962228042763,\n",
              " 0.1952467501635101,\n",
              " 0.1968041239692297,\n",
              " 0.19833761398909763,\n",
              " 0.19982137426127566,\n",
              " 0.20124399524342343,\n",
              " 0.20260164304851222,\n",
              " 0.2038944793833359,\n",
              " 0.20512473025712755]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXrdqzlXT40K",
        "outputId": "7465417f-fcca-4862-ccf0-96569a238776"
      },
      "source": [
        "w"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.9614598 ,  0.51639087,  0.55195919,  0.58441126,  0.00361527,\n",
              "        1.15805014, -0.97031441, -0.01590801,  0.63459101,  0.00253758,\n",
              "        0.08559798, -0.05271091,  0.11033811,  0.52196915,  0.50048329])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pOF35CYyU4zM",
        "outputId": "cede80bf-c4e8-4d03-d2a0-cc4787eb6c04"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(epochs),training_loss)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7c9bce5890>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C-0Fp_YVjY8",
        "outputId": "45b74f3c-4ff0-490b-aa47-63aab7d62873"
      },
      "source": [
        "np.random.choice(range(N))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2edfe7-d6fd-4f02-dc19-ab743bd00f05"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.07138797, -0.11523275,  0.62790063, -0.04665982,  0.38795902,\n",
              "          0.22569771, -0.0745792 ,  0.05749721,  0.22867684, -0.41746152,\n",
              "         -0.16162345, -0.1031729 ,  0.19911798, -0.01884737,  0.43404441]]),\n",
              " array([-0.35445735]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k28U1xDsLIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMokBfs3-2PY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}